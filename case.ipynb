{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 00:57:56.256114: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-23 00:57:56.389531: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-23 00:57:56.393290: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-23 00:57:56.393314: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-23 00:57:57.052266: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-23 00:57:57.052420: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-23 00:57:57.052427: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Assume a collection of playlists, P (which they refer to as the Case Base).\n",
    "\n",
    "# User inputs to the algorithm:\n",
    "# - seed song (s)\n",
    "# - desired length (N)\n",
    "# Hyperparameter (k)\n",
    "\n",
    "import pandas as pd\n",
    "import os, sys, time, random\n",
    "import json\n",
    "import numpy as np\n",
    "import keras\n",
    "import sqlite3\n",
    "import math\n",
    "import functools\n",
    "import operator\n",
    "import asyncio\n",
    "\n",
    "k = 20\n",
    "# seed = 'spotify:track:6I9VzXrHxO9rA9A5euc8Ak' # Britney Spears - Toxic\n",
    "seed = 'spotify:track:4aVuWgvD0X63hcOCnZtNFA' # Toto - Hold the Line\n",
    "conn = sqlite3.connect(\"/mnt/z/other/spotify_backup.db\", check_same_thread=False)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_attr(l, gamma, delta):\n",
    "    mul_attr = 1\n",
    "    i = 0\n",
    "    while i < len(l) - 1:\n",
    "        j = i + 1\n",
    "        while j < len(l) and j - i < gamma:\n",
    "            if l[j] != 0 and l[i] != 0 and abs(l[j] - l[i]) > delta:\n",
    "                mul_attr *= ((j-i) / gamma)\n",
    "                break\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    return mul_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var(p): # todo: fine-tuning deltas and gammas\n",
    "    con = sqlite3.connect(\"/mnt/z/other/spotify_backup.db\", check_same_thread=False)\n",
    "    c = con.cursor()\n",
    "    delta_diffs = [0.25, 0.25, 0.25, 0.25, 0.25]\n",
    "    gammas = [3, 3, 3, 3, 3]\n",
    "    feature_list = np.array(c.execute(f\"SELECT tf.acousticness, tf.instrumentalness, tf.speechiness, tf.energy, tf.valence FROM track_features as tf JOIN playlist_tracks as pt WHERE tf.track_uri = pt.track_uri AND pt.pid = '{p}' ORDER BY pt.pindex ASC;\").fetchall()).transpose()\n",
    "    total_attrs = [var_attr(feature_list[i], gammas[i], delta_diffs[i]) for i in range(len(gammas))]\n",
    "    total = 1\n",
    "    for attr in total_attrs:\n",
    "        total *= attr\n",
    "\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rel(q, t, checked=True):\n",
    "    con = sqlite3.connect(\"/mnt/z/other/spotify_backup.db\", check_same_thread=False)\n",
    "    c = con.cursor()\n",
    "    if not checked:\n",
    "        if t in q:\n",
    "            phi = int(c.execute(f\"SELECT COUNT(*) FROM seq2_simple WHERE track_uri1 = '{q[0]}' AND track_uri2 = '{q[1]}';\").fetchone()[0])\n",
    "        else:\n",
    "            return -1 # t not in q error\n",
    "    else:\n",
    "        phi = int(c.execute(f\"SELECT COUNT(*) FROM seq2_simple WHERE track_uri1 = '{q[0]}' AND track_uri2 = '{q[1]}';\").fetchone()[0])\n",
    "    \n",
    "    if False: # future variability in pattern size, adding weighting based on length\n",
    "        alpha = 0.5\n",
    "        theta = 2\n",
    "        lq = len(q)\n",
    "    \n",
    "    beta = 0.5 # popularity weighting\n",
    "    psi = 0\n",
    "    x = q[0]\n",
    "    if q[0] == t:\n",
    "        x = q[1]\n",
    "\n",
    "    psi = pow(int(c.execute(f\"SELECT COUNT(*) FROM playlist_tracks WHERE track_uri = '{x}';\").fetchone()[0]), beta)\n",
    "    rel = phi / psi\n",
    "\n",
    "    return rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' for seq2_occurences not seq2_simple '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' for seq2_occurences not seq2_simple '''\n",
    "# def rel(q, t, checked=True):\n",
    "#     if not checked:\n",
    "#         if t in q:\n",
    "#             phi = int(cur.execute(f\"SELECT prevalence FROM seq2_occurences WHERE track_uri1 = '{q[0]}' AND track_uri2 = '{q[1]}';\").fetchone()[0])\n",
    "#         else:\n",
    "#             return -1 # t not in q error\n",
    "#     else:\n",
    "#         phi = int(cur.execute(f\"SELECT prevalence FROM seq2_occurences WHERE track_uri1 = '{q[0]}' AND track_uri2 = '{q[1]}';\").fetchone()[0])\n",
    "    \n",
    "#     if False: # future variability in pattern size, adding weighting based on length\n",
    "#         alpha = 0.5\n",
    "#         theta = 2\n",
    "#         lq = len(q)\n",
    "    \n",
    "#     beta = 0.5 # popularity weighting\n",
    "#     psi = 0\n",
    "#     x = q[0]\n",
    "#     if q[0] == t:\n",
    "#         x = q[1]\n",
    "\n",
    "#     psi = pow(int(cur.execute(f\"SELECT COUNT(*) FROM playlist_tracks WHERE track_uri = '{x}';\").fetchone()[0]), beta)\n",
    "#     rel = phi / psi\n",
    "\n",
    "#     return rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# containing = cur.execute(f\"SELECT pid, pindex FROM playlist_tracks WHERE track_uri = '{seed}';\").fetchall()\n",
    "# totals = []\n",
    "# for c in containing:\n",
    "#     rel_prev = 0\n",
    "#     rel_after = 0\n",
    "#     prev = cur.execute(f\"SELECT track_uri FROM playlist_tracks WHERE pid = '{c[0]}' AND pindex+1 = '{c[1]}';\").fetchone()\n",
    "#     after = cur.execute(f\"SELECT track_uri FROM playlist_tracks WHERE pid = '{c[0]}' AND pindex-1 = '{c[1]}';\").fetchone()\n",
    "#     occurences = 0\n",
    "#     if prev is not None:\n",
    "#         rel_prev = rel([prev[0], seed], seed)\n",
    "#     if after is not None:\n",
    "#         rel_after = rel([seed, after[0]], seed)\n",
    "\n",
    "#     coherence = rel_prev + rel_after\n",
    "#     variety = var(c[0])\n",
    "    \n",
    "#     rho = variety * coherence\n",
    "#     totals.append([c, rho])\n",
    "    \n",
    "# containing_sorted = sorted(totals, key = lambda prevalence: prevalence[1], reverse=True)\n",
    "\n",
    "# best_k_playlists = [p[0] for p in containing_sorted[:k]] # list of k sorted playlist pids\n",
    "# best_k_playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0, 'spotify:track:0UaMYEvWZi0ZqiDOoHU3YI'), (2, 9, 'spotify:track:7tIJDktakabGoHjwTTa35W'), (3, 45, 'spotify:track:0tOyrixMQ17NUznPIxYtVD'), (5, 2, 'spotify:track:1V4jC0vJ5525lEF1bFgPX2')]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "from multiprocessing import Process\n",
    "def test(x):\n",
    "    con = sqlite3.connect(\"/mnt/z/other/spotify_backup.db\", check_same_thread=False)\n",
    "    c = con.cursor()\n",
    "    return c.execute(f\"SELECT * FROM playlist_tracks LIMIT {x}, 100;\").fetchall()[0]\n",
    "\n",
    "with Pool(5) as p:\n",
    "        print(p.map(test, [0, 100, 200, 300]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "containing = cur.execute(f\"SELECT pid, pindex FROM playlist_tracks WHERE track_uri = '{seed}';\").fetchall()\n",
    "totals = []\n",
    "\n",
    "prev_cases = [f\"(pid = {c[0]} AND pindex-1 = {c[1]})\" for c in containing]\n",
    "prev_split = []\n",
    "for x in range(0, len(prev_cases), 900):\n",
    "    prev_split.append(\"OR\".join(prev_cases[x:x+900]))\n",
    "\n",
    "after_cases = [f\"(pid = {c[0]} AND pindex+1 = {c[1]})\" for c in containing]\n",
    "after_split = []\n",
    "for x in range(0, len(after_cases), 900):\n",
    "    after_split.append(\"OR\".join(after_cases[x:x+900]))\n",
    "\n",
    "def fetch(x):\n",
    "    con = sqlite3.connect(\"/mnt/z/other/spotify_backup.db\", check_same_thread=False)\n",
    "    c = con.cursor()\n",
    "    return c.execute(f\"SELECT pid, track_uri FROM playlist_tracks WHERE {x} ORDER BY pid;\").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(prev_split))\n",
    "print(len(after_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetched_prev_tracks = []\n",
    "fetched_after_tracks = []\n",
    "# with Pool() as p:\n",
    "# with Pool((max(len(prev_cases), len(after_cases)) // 900)*2) as p:\n",
    "with Pool(len(prev_split) + len(after_split)) as p:\n",
    "    fetched_prev_tracks = p.map_async(fetch, prev_split)\n",
    "    fetched_after_tracks = p.map_async(fetch, after_split)\n",
    "\n",
    "    p.close()\n",
    "    p.join()\n",
    "\n",
    "# fetched_after_tracks.wait()\n",
    "# fetched_prev_tracks.wait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetched_prev_tracks = [item for sublist in fetched_prev_tracks.get() for item in sublist]\n",
    "fetched_after_tracks = [item for sublist in fetched_after_tracks.get() for item in sublist]\n",
    "\n",
    "fetched_prev_tracks = dict(fetched_prev_tracks)\n",
    "fetched_after_tracks = dict(fetched_after_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rpp(i):\n",
    "# for i in fetched_prev_tracks.keys() & fetched_after_tracks.keys():\n",
    "    # rel_prev = Process(target=rel, args=([fetched_prev_tracks[i], seed], seed))\n",
    "    # rel_prev.run()\n",
    "\n",
    "    # rel_after = Process(target=rel, args=([seed, fetched_after_tracks[i]], seed))\n",
    "    # rel_after.run()\n",
    "    rel_prev = rel([fetched_prev_tracks[i], seed], seed)\n",
    "    rel_after = rel([seed, fetched_after_tracks[i]], seed)\n",
    "    # with Pool(2) as q:\n",
    "    #     rel_prev, rel_after = q.map(rel, [([fetched_prev_tracks[i], seed], seed),([seed, fetched_after_tracks[i]], seed)])\n",
    "\n",
    "    coherence = rel_prev + rel_after\n",
    "    variety = var(i)\n",
    "    \n",
    "    rho = variety * coherence\n",
    "    # totals.append([i, rho])\n",
    "    return [i, rho]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rpp_before(i):\n",
    "# for i in fetched_prev_tracks.keys() - fetched_after_tracks.keys():\n",
    "    rel_prev = rel([fetched_prev_tracks[i], seed], seed)\n",
    "\n",
    "    variety = var(i)\n",
    "    \n",
    "    rho = variety * rel_prev\n",
    "    # totals.append([i, rho])\n",
    "    return [i, rho]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rpp_after(i):\n",
    "# for i in fetched_after_tracks.keys() - fetched_prev_tracks.keys():\n",
    "    rel_after = rel([fetched_prev_tracks[i], seed], seed)\n",
    "\n",
    "    variety = var(i)\n",
    "    \n",
    "    rho = variety * rel_after\n",
    "    # totals.append([i, rho])\n",
    "    return [i, rho]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn.close()\n",
    "# conn = sqlite3.connect(\"/mnt/z/other/spotify_backup.db\", check_same_thread=False)\n",
    "# cur = conn.cursor()\n",
    "# c = cur.execute(\"SELECT * FROM tracks LIMIT 20;\").fetchall()\n",
    "# print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18657/1916638705.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# with Pool(len(fetched_prev_tracks.keys()) - len(intersection)) as p:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mCLOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"In unknown state\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "intersection = fetched_prev_tracks.keys() & fetched_after_tracks.keys()\n",
    "# with Pool(len(set(fetched_prev_tracks.keys()).union(set(fetched_after_tracks.keys())))) as p:\n",
    "with Pool(16) as p:\n",
    "    t1 = p.map_async(rpp, intersection)\n",
    "    t2 = p.map_async(rpp_before, fetched_prev_tracks.keys() - fetched_after_tracks.keys())\n",
    "    t3 = p.map_async(rpp_after, fetched_after_tracks.keys() - fetched_prev_tracks.keys())\n",
    "\n",
    "    p.close()\n",
    "    p.join()\n",
    "\n",
    "# with Pool(len(fetched_prev_tracks.keys()) - len(intersection)) as p:\n",
    "# with Pool(10) as p2:\n",
    "# with Pool(len(fetched_prev_tracks.keys()) - len(intersection)) as p:\n",
    "# with Pool(10) as p3:\n",
    "totals = t1.get() + t2.get() + t3.get()\n",
    "containing_sorted = sorted(totals, key = lambda prevalence: prevalence[1], reverse=True)\n",
    "\n",
    "best_k_playlists = [p[0] for p in containing_sorted[:k]] # list of k sorted playlist pids\n",
    "best_k_playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_k_playlists_string = \", \".join([f\"'{b}'\" for b in best_k_playlists])\n",
    "candidate_songs = [s[0] for s in cur.execute(f\"SELECT DISTINCT track_uri FROM playlist_tracks WHERE pid in ({best_k_playlists_string});\").fetchall()]\n",
    "current_playlist = [seed]\n",
    "candidate_playlists = [current_playlist]\n",
    "candidate_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pair(x, y): # check whether sequence <x, y> occurs in any of the k retrieved playlists and count them\n",
    "    occurences = 0\n",
    "    containing_playlists = [c for c in cur.execute(f\"SELECT p1.pid, p1.pindex, p2.index FROM playlist_tracks as p1 JOIN playlist_tracks as p2 WHERE p1.track_uri = {x} AND p2.track_uri = {y} AND p1.pid = p2.pid AND p1.pid in ({best_k_playlists_string}));\")]\n",
    "    for playlist in containing_playlists:\n",
    "        if playlist[1] == playlist[2] - 1:\n",
    "            # return 1\n",
    "            occurences += 1\n",
    "            \n",
    "    return occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(T_prime, seq, u):\n",
    "    r = rel(seq, u) # relevance of pattern seq to added song u\n",
    "    return r * var(T_prime)\n",
    "\n",
    "    # todo: look-ahead factor L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 8\n",
    "while len(current_playlist) < N:\n",
    "    t = current_playlist[0]\n",
    "    T = current_playlist[-1]\n",
    "    successors_of_current_playlist = []\n",
    "    for u in candidate_songs:\n",
    "        pre_occurences = check_pair(u, t)\n",
    "        if pre_occurences > 0:\n",
    "            successor_playlist = [u] + current_playlist\n",
    "            successors_of_current_playlist.append([pre_occurences, successor_playlist, [u,current_playlist[0]]])\n",
    "        post_occurences = check_pair(T, u)\n",
    "        if post_occurences > 0:\n",
    "            successor_playlist = current_playlist + [u]\n",
    "            successors_of_current_playlist.append([post_occurences, successor_playlist, [current_playlist[-1],u]])\n",
    "    if len(successors_of_current_playlist) + len(successors_of_current_playlist) == 0:\n",
    "        # discard current_playlist\n",
    "        print(\"failed to create playlist\")\n",
    "    else: # pop new current_playlist from candidate_playlists\n",
    "    \t# sort successors_of_current_playlist using some measure of quality \n",
    "        for x in range(len(successors_of_current_playlist)): # todo: more efficient var check?\n",
    "            successors_of_current_playlist[x][3] = h(successors_of_current_playlist[x][1], successors_of_current_playlist[x][2], u)\n",
    "        \n",
    "        successors_of_current_playlist = sorted(successors_of_current_playlist, key=lambda x: x[3], reverse=True)\n",
    "        print(successors_of_current_playlist)\n",
    "        current_playlist = successors_of_current_playlist[0][1]\n",
    "        saved_playlists = successors_of_current_playlist[1::]\n",
    "        # insert the saved_playlists into candidate_playlists\n",
    "        candidate_playlists += saved_playlists\n",
    "        # In fact, they should be inserted in such a way as to keep candidate_playlists \n",
    "        # ordered also by their quality, but ignore this for now\n",
    "\n",
    "# If we reach here, we exited the loop, i.e. we have a playlist of length L\n",
    "print(current_playlist)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ce05d1cbf6f1f6498009ed575757a95597cd8f279cd92e55bb3c5a95c156e1de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
